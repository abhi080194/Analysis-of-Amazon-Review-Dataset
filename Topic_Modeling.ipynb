{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing required pakages for text processing \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download(\"stopwords\")\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "#import ijson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10261"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading a single json file\n",
    "data = pd.read_json('dataset/Musical_Instruments_5.json', lines = True)\n",
    "data1= pd.DataFrame.from_dict(data, orient='columns')\n",
    "len(data1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#removing the stop words\n",
    "nltk_stpwd = stopwords.words('english')\n",
    "stop_words_stpwd = get_stop_words('en')\n",
    "merged_stopwords = list(set(nltk_stpwd + stop_words_stpwd))\n",
    "\n",
    "#print(len(set(merged_stopwords)))\n",
    "#print(merged_stopwords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sb_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_reviews = data1.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_set = [data1.reviewText[i] for i in range(num_reviews)]\n",
    "#doc_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.9 s, sys: 2.02 s, total: 24.9 s\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#time taken to tokenize on a single core\n",
    "texts = []\n",
    "\n",
    "for doc in doc_set:\n",
    "    # putting our three steps together\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    stopped_tokens = [token for token in tokens if not token in merged_stopwords]\n",
    "    stemmed_tokens = [sb_stemmer.stem(token) for token in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_and_pos_tag(doc):\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    stopped_tokens = [token for token in tokens if not token in merged_stopwords]\n",
    "    stemmed_tokens = [sb_stemmer.stem(token) for token in stopped_tokens]\n",
    "    return stemmed_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 220 ms, sys: 180 ms, total: 400 ms\n",
      "Wall time: 5.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#time taken on \n",
    "from multiprocessing import Pool\n",
    "pool = Pool(processes=6)\n",
    "tokens = pool.map(tokenize_and_pos_tag, doc_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in tokens:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "          for text in tokens]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gensim's Dictionary encapsulates the mapping between normalized words and their integer ids.\n",
    "texts_dict = corpora.Dictionary(texts)\n",
    "#texts_dict.save('auto_review.dict') # lets save to disk for later use\n",
    "# Examine each tokenâ€™s unique id\n",
    "#print(texts_dict)\n",
    "#print(texts_dict.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import operator\n",
    "#texts_dict.filter_extremes(no_below=30, no_above=0.15) # inlace filter#\n",
    "#print(texts_dict)\n",
    "#print(\"top terms:\")\n",
    "#print(sorted(texts_dict.token2id.items(), key=operator.itemgetter(1), reverse = False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10261"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [texts_dict.doc2bow(text) for text in texts]\n",
    "len(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482.800997019\n"
     ]
    }
   ],
   "source": [
    "## Topic Modeling on single core\n",
    "import time\n",
    "start_time = time.time()\n",
    "lda_model = gensim.models.LdaModel(corpus,  num_topics=5, id2word=texts_dict, passes=20)\n",
    "print(time.time() - start_time)\n",
    "## the time is shown in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.024*\"pedal\" + 0.021*\"sound\" + 0.019*\"amp\" + 0.014*\"use\" + 0.011*\"like\"'),\n",
       " (1,\n",
       "  u'0.059*\"string\" + 0.029*\"guitar\" + 0.023*\"sound\" + 0.019*\"play\" + 0.012*\"tune\"'),\n",
       " (2,\n",
       "  u'0.022*\"guitar\" + 0.015*\"work\" + 0.015*\"one\" + 0.014*\"strap\" + 0.013*\"good\"'),\n",
       " (3,\n",
       "  u'0.022*\"tuner\" + 0.019*\"use\" + 0.017*\"record\" + 0.011*\"one\" + 0.009*\"tune\"'),\n",
       " (4,\n",
       "  u'0.026*\"pick\" + 0.022*\"stand\" + 0.022*\"capo\" + 0.021*\"use\" + 0.020*\"guitar\"')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model for 5 words and 5 topics\n",
    "lda_model.show_topics(num_words=5, num_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 27s, sys: 19.2 s, total: 3min 47s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Multicore Topic Modeling with time taken in minutes\n",
    "#import time\n",
    "#start_time = time.time()\n",
    "lda = gensim.models.LdaMulticore(corpus, id2word=texts_dict, num_topics=5, passes=20, workers=5)\n",
    "#print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.018*\"use\" + 0.014*\"record\" + 0.007*\"work\" + 0.007*\"get\" + 0.006*\"one\"'),\n",
       " (1,\n",
       "  u'0.025*\"guitar\" + 0.015*\"one\" + 0.014*\"use\" + 0.011*\"work\" + 0.010*\"well\"'),\n",
       " (2,\n",
       "  u'0.049*\"string\" + 0.020*\"guitar\" + 0.018*\"use\" + 0.016*\"tune\" + 0.016*\"tuner\"'),\n",
       " (3,\n",
       "  u'0.023*\"sound\" + 0.017*\"use\" + 0.017*\"mic\" + 0.015*\"amp\" + 0.010*\"record\"'),\n",
       " (4,\n",
       "  u'0.032*\"pedal\" + 0.017*\"sound\" + 0.014*\"use\" + 0.013*\"amp\" + 0.012*\"like\"')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lda model for 5 words and 5 topics \n",
    "lda.show_topics(num_words=5, num_topics=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
