{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make sure pymongo works\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#connecting my pc to mongoDB database\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sibbu\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "#tokenizing words for text processing\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download(\"stopwords\")\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "#import ijson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specifying the database\n",
    "db = client['Amazon_Reviews']\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'Amazon_Reviews'), 'All_Reviews')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specifying the collection to be used in the database\n",
    "collection = db['All_Reviews']\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5a332d0e5132162d811c8f3c'),\n",
       " 'asin': 'B000H00VBQ',\n",
       " 'helpful': [0, 0],\n",
       " 'overall': 4.0,\n",
       " 'reviewText': 'Mysteries are interesting.  The tension between Robson and the tall blond is good but not always believable.  She often seemed uncomfortable.',\n",
       " 'reviewTime': '10 30, 2013',\n",
       " 'reviewerID': 'A1RJPIGRSNX4PW',\n",
       " 'reviewerName': 'J. Kaplan \"JJ\"',\n",
       " 'summary': 'Robson Green is mesmerizing',\n",
       " 'unixReviewTime': 1383091200}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing if able to query from the databse by printing the first row\n",
    "data = collection.find_one()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Fetching summary for different ratings by varying the overall variable value as 1,2,3,4,5\n",
    "#change the overall value to 1,2,3,4,5 to obtain the summary for those ratings\n",
    "Review_rating_1 = list(collection.find({'overall':5}, {'summary': 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10351164"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Review_rating_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(Review_rating_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#doing text processing, tokenizing, removing stop words, stemming the words \n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "nltk_stpwd = stopwords.words('english')\n",
    "stop_words_stpwd = get_stop_words('en')\n",
    "merged_stopwords = list(set(nltk_stpwd + stop_words_stpwd))\n",
    "sb_stemmer = SnowballStemmer('english')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_reviews = df1.shape[0]\n",
    "num_reviews\n",
    "doc_set = [df1.summary[i] for i in range(num_reviews)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['robson', 'green', 'great', 'write']\n",
      "Wall time: 18min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "texts = []\n",
    "for doc in doc_set:\n",
    "    # putting our three steps together\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    stopped_tokens = [token for token in tokens if not token in merged_stopwords]\n",
    "    stemmed_tokens = [sb_stemmer.stem(token) for token in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n",
    "print (texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 793215),\n",
       " ('book', 764861),\n",
       " ('read', 584972),\n",
       " ('good', 508208),\n",
       " ('best', 370175),\n",
       " ('excel', 297064),\n",
       " ('stori', 281664),\n",
       " ('one', 250778),\n",
       " ('work', 247394),\n",
       " ('awesom', 216525),\n",
       " ('fun', 197242),\n",
       " ('seri', 195162),\n",
       " ('perfect', 173108),\n",
       " ('wonder', 168843),\n",
       " ('amaz', 162717),\n",
       " ('anoth', 142461),\n",
       " ('must', 140931),\n",
       " ('well', 133340),\n",
       " ('nice', 132641)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting word count and printing top 20 for specified rating\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "sortedwordcount = sorted(frequency.items(), key=lambda k_v: k_v[1], reverse=True) \n",
    "sortedwordcount[1:20]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
